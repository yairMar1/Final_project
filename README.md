# ğŸ›¡ï¸ Beyond GLASS-FOOD: Smarter Self-Supervised Spam Detection

## ğŸ‘¨â€ğŸ’» Authors
- Yuval Vogdan  
- Yair Margalit  
- Avichai Benâ€“David  

### ğŸ“ Instructor
Or Haim Anidjar

---

# ğŸ“ Project Overview
This project introduces an **Iterative Self Improving (ISD)** framework for SMS spam detection.  
Building upon the *GLASS-FOOD* concept, we developed a dynamic pipeline that treats spam as **Out-of-Distribution (OOD)** data.

Unlike static models, our system **learns from its own mistakes**:  
- It identifies the hardest examples it failed to classify  
- Uses an LLM to generate similar synthetic spam  
- Retrains itself iteratively to become more robust over time  

---

# ğŸ¯ Key Highlights
- **State-of-the-art Architecture:**  
  Replaced traditional GANs with **DeBERTaâ€‘v3** (Discriminator) and **Mistralâ€‘7B** (Generator).

- **Self-Improving Loop:**  
  Hard-mining engine that targets blind spots (False Negatives & borderline cases).

- **Advanced OOD Metrics:**  
  Energy Scores & Mahalanobis Distance for precise uncertainty estimation.

- **Near Perfect Results:**  
  F1â€‘Score **0.9965** and Precision **1.0** after 5 iterations.

---

# âš™ï¸ System Architecture & Generation Modes

## ğŸ§  The Discriminator â€” DeBERTaâ€‘v3
Acts as the systemâ€™s â€œbrainâ€:  
- Classifies messages  
- Produces uncertainty signals (Energy Score, Mahalanobis Distance)  
- Identifies where it struggles most  

## ğŸ” Hard-Mining Engine
A logic layer that:  
- Analyzes classifier performance  
- Extracts **Critical Failures** (False Negatives)  
- Detects **Borderline Cases**  
- Feeds them back into the generation loop  

## ğŸ¤– The Generator â€” Mistralâ€‘7Bâ€‘v3 instruct

### ğŸŒ Full Mode â€” General Exploration
- Generates diverse, highâ€‘quality spam  
- Provides *breadth* and wide scenario coverage  

### ğŸ¯ Hard Mode â€” Targeted Exploitation
- Receives the hardest examples from the miner  
- Produces sophisticated variations of those exact messages  
- Sharpens the discriminatorâ€™s weak points  

---

# ğŸ”„ The Iterative Loop (ISD)
1. **Train:** Discriminator learns on the current dataset  
2. **Mine:** Hard-Miner identifies challenging/OOD samples  
3. **Generate:**  
   - Full Mode â†’ general spam  
   - Hard Mode â†’ targeted â€œclonesâ€ of hard samples  
4. **Augment & Repeat:**  
   Clean, validate, and add new data for the next iteration  

---

# ğŸ› ï¸ Tech Stack
- **Language:** Python  
- **LLM:** Mistralâ€‘7Bâ€‘v3â€‘Instruct  
- **Transformers:** DeBERTaâ€‘v3â€‘base, RoBERTa  
- **Libraries:** HuggingFace, pandas, transformers, sklearn, torch, numpy  
- **Techniques:**  Label Smoothing, Temperature Scaling, Backâ€‘Translation, OOD Detection  

---

# ğŸ“Š Results

## ğŸ“ˆ Performance Over Iterations

| Metric     | GLASSâ€‘FOOD (replica) | ISD (1st Iteration) | ISD (5th Iteration) |
|------------|-----------------------|-----------------------|----------------------|
| Accuracy   | 0.9995                | 0.9996                | 0.9999               |
| Precision  | 0.9861                | 0.9797                | 1.0                  |
| F1â€‘Score   | 0.9793                | 0.9863                | 0.9965               |
| Recall     | 0.9726                | 0.9931                | 0.9931               |

**Key Finding:**  
The iterative framework significantly outperforms static augmentation methods, proving that **dynamic, selfâ€‘corrective learning** is superior for spam detection.

---

# ğŸš€ Future Work
- **Model Compression:** MobileBERT / Quantization for on-device deployment  
- **Multilingual Support:** Hebrew, Arabic, Spanish  
- **Crossâ€‘Domain Expansion:** Email, WhatsApp datasets